import re
from collections import OrderedDict  # NEW: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
import pandas as pd
import streamlit as st
import plotly.express as px
from utils.filters import cascading_filter


class FiberflappingAnalyzer:
    """
    ‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö logic ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fiber Flapping:
      - ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°/normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• OSC Optical ‡πÅ‡∏•‡∏∞ FM
      - ‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà Max-Min(dB) > threshold
      - ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà '‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ alarm match'
      - ‡πÄ‡∏û‡∏¥‡πà‡∏° Site Name ‡∏à‡∏≤‡∏Å reference file
      - ‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡∏≤‡∏£‡∏≤‡∏á highlight + KPI ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô + ‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏ß‡∏° 7 ‡∏ß‡∏±‡∏ô

    ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
        analyzer = FiberflappingAnalyzer(df_optical, df_fm, threshold=2.0)
        analyzer.process()
    """

    # -------------------- Regex --------------------
    # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏ô‡∏î‡∏ó‡∏µ‡πà‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ _A ‡∏´‡∏£‡∏∑‡∏≠ _R ‡πÄ‡∏ä‡πà‡∏ô CR_WCO_7807_031_1Z_A / SR_WCO_9006_043_1Z_A
    _NODE_PATTERN = re.compile(r'[A-Z]{2}_[A-Z0-9]+_\d{3,4}_[0-9]{3}_[0-9A-Z]+_[AR]')

    def __init__(self, df_optical: pd.DataFrame, df_fm: pd.DataFrame, threshold: float = 2.0, ref_path: str = "data/Flapping.xlsx"):
        self.df_optical_raw = df_optical
        self.df_fm_raw = df_fm
        self.threshold = threshold
        self.ref_path = ref_path
        self.df_ref = None  # Reference data for site names
        self.daily_tables = None  # NEW: ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export/report

     

    # -------------------- Load Reference --------------------
    def _load_reference(self) -> pd.DataFrame:
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå reference ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö site names (‡∏•‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á Flapping.xlsx ‡πÅ‡∏•‡∏∞ flapping.xlsx)"""
        primary_path = self.ref_path
        try:
            df_ref = pd.read_excel(primary_path)
            df_ref.columns = df_ref.columns.str.strip()
            return df_ref
        except Exception as e_primary:
            # fallback: toggle filename case for compatibility
            alt_path = None
            if primary_path.endswith("Flapping.xlsx"):
                alt_path = primary_path.replace("Flapping.xlsx", "flapping.xlsx")
            elif primary_path.endswith("flapping.xlsx"):
                alt_path = primary_path.replace("flapping.xlsx", "Flapping.xlsx")

            if alt_path:
                try:
                    df_ref = pd.read_excel(alt_path)
                    df_ref.columns = df_ref.columns.str.strip()
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï ref_path ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
                    self.ref_path = alt_path
                    return df_ref
                except Exception as e_alt:
                    st.warning(f"Could not load reference file {primary_path} or fallback {alt_path}: {e_alt}")
                    return pd.DataFrame()
            else:
                st.warning(f"Could not load reference file {primary_path}: {e_primary}")
                return pd.DataFrame()

    # -------------------- Helpers --------------------
    @staticmethod
    def _extract_target_from_measure_object(measure_obj: str) -> str | None:
        """‡∏î‡∏∂‡∏á Target ME ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏Ç‡∏≠‡∏á Measure Object"""
        m = re.search(r"\(([^)]+)\)", str(measure_obj))
        return m.group(1) if m else None

    def _extract_nodes_from_link(self, link_val: str) -> tuple[str | None, str | None]:
        """
        ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏ô‡∏î 2 ‡∏ï‡∏±‡∏ß‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Link ‡∏Ç‡∏≠‡∏á FM
        ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ (fm_node1, fm_node2) ‡∏´‡∏£‡∏∑‡∏≠ (None, None) ‡∏ñ‡πâ‡∏≤‡∏î‡∏∂‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
        - ‡πÉ‡∏ä‡πâ regex ‡∏´‡∏≤ token ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ME/Target (‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ _A/_R)
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è
        """
        if pd.isna(link_val):
            return (None, None)
        s = str(link_val)
        nodes = self._NODE_PATTERN.findall(s)
        if len(nodes) >= 2:
            return (nodes[0], nodes[1])
        return (None, None)

    # -------------------- Normalize / Prepare --------------------
    def normalize_optical(self) -> pd.DataFrame:
        df = self.df_optical_raw.copy()
        df.columns = df.columns.str.strip()

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Max - Min (dB)
        df["Max - Min (dB)"] = (
            df["Max Value of Input Optical Power(dBm)"]
            - df["Min Value of Input Optical Power(dBm)"]
        )

        # Extract Target ME ‡∏à‡∏≤‡∏Å Measure Object: ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö
        df["Target ME"] = df["Measure Object"].apply(self._extract_target_from_measure_object)

        # ‡πÄ‡∏û‡∏¥‡πà‡∏° Site Name ‡∏à‡∏≤‡∏Å reference
        self.df_ref = self._load_reference()
        if not self.df_ref.empty and "ME" in self.df_ref.columns and "Site Name" in self.df_ref.columns:
            # Merge ‡∏Å‡∏±‡∏ö reference ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° Site Name
            df = df.merge(
                self.df_ref[["ME", "Site Name"]],
                left_on="ME",
                right_on="ME",
                how="left"
            )
        else:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ reference ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ ME ‡πÄ‡∏õ‡πá‡∏ô Site Name
            df["Site Name"] = df["ME"]

        # ‡πÄ‡∏ß‡∏•‡∏≤‡∏ä‡πà‡∏ß‡∏á Begin/End
        df["Begin Time"] = pd.to_datetime(df["Begin Time"], errors="coerce")
        df["End Time"] = pd.to_datetime(df["End Time"], errors="coerce")
        return df

    def normalize_fm(self) -> tuple[pd.DataFrame, str]:
        df = self.df_fm_raw.copy()
        df.columns = df.columns.str.strip()

        df["Occurrence Time"] = pd.to_datetime(df["Occurrence Time"], errors="coerce")
        df["Clear Time"] = pd.to_datetime(df["Clear Time"], errors="coerce")

        # ‡∏´‡∏≤ column ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ "Link"
        link_cols = [c for c in df.columns if str(c).startswith("Link")]
        if not link_cols:
            raise ValueError("No 'Link*' column found in FM Alarm file.")
        link_col = link_cols[0]

        # ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° fm_node1, fm_node2 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏ì‡∏∞‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
        fm_nodes = df[link_col].apply(self._extract_nodes_from_link)
        df["fm_node1"] = fm_nodes.apply(lambda x: x[0])
        df["fm_node2"] = fm_nodes.apply(lambda x: x[1])

        return df, link_col

    # -------------------- Core Filtering --------------------
    def filter_optical_by_threshold(self, df_optical_norm: pd.DataFrame) -> pd.DataFrame:
        """
        ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Optical:
          1. ‡∏ï‡∏±‡∏î‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà Min Value = -60 (‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì)
          2. ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà Max - Min (dB) > threshold
        """
        df = df_optical_norm.copy()

        # 1Ô∏è‚É£ ‡∏ï‡∏±‡∏î‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà Min Value = -60
        if "Min Value of Input Optical Power(dBm)" in df.columns:
            before = len(df)
            df = df[df["Min Value of Input Optical Power(dBm)"] != -60]
            after = len(df)
            print(f"üîπ Filtered out {before - after} rows where Min Value = -60 dBm")

        # 2Ô∏è‚É£ ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° threshold
        df_filtered = df[df["Max - Min (dB)"] > self.threshold].copy()

        print(f"‚úÖ Remaining rows after threshold filter: {len(df_filtered)}")
        return df_filtered


    def find_nomatch(self, df_filtered: pd.DataFrame, df_fm_norm: pd.DataFrame, link_col: str) -> pd.DataFrame:
        """
        Logic ‡πÉ‡∏´‡∏°‡πà: ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏µ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß ‡πÇ‡∏î‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö '‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î' ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Link ‡∏Ç‡∏≠‡∏á FM (‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏î‡πâ)
        ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î‡πÉ‡∏ô FM ‚Üí FLAPPING
        ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ß‡∏•‡∏≤ overlap:
            Occurrence Time <= End Time ‡πÅ‡∏•‡∏∞ Clear Time >= Begin Time
            - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡πÅ‡∏ñ‡∏ß overlap ‚Üí MATCHED (not flapping)
            - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ overlap ‡πÄ‡∏•‡∏¢ ‚Üí FLAPPING
        ‡∏û‡∏¥‡∏°‡∏û‡πå log ‡∏•‡∏á terminal ‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ
        """
        result_rows = []

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ FM rows ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏´‡∏ô‡∏î‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏Ç‡πâ‡∏≤‡∏á
        fm_valid = df_fm_norm.dropna(subset=["fm_node1", "fm_node2"]).copy()

        for idx, row in df_filtered.reset_index(drop=True).iterrows():
            node_a = str(row.get("ME", "")).strip()
            node_b = str(row.get("Target ME", "")).strip()
            begin_t = row.get("Begin Time", pd.NaT)
            end_t = row.get("End Time", pd.NaT)

            # ‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ node ‡πÉ‡∏î node ‡∏´‡∏ô‡∏∂‡πà‡∏á
            if not node_a or not node_b or pd.isna(begin_t) or pd.isna(end_t):
                print(f"Row {idx}: ‚ö†Ô∏è Missing fields ‚Üí ME='{node_a}', Target='{node_b}', Begin='{begin_t}', End='{end_t}' ‚Üí Treat as FLAPPING")
                result_rows.append(row)
                continue

            # ‡∏´‡∏≤ FM ‡∏ó‡∏µ‡πà‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î‡∏ï‡∏£‡∏á (‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏î‡πâ)
            fm_pair_mask = (
                ((fm_valid["fm_node1"] == node_a) & (fm_valid["fm_node2"] == node_b)) |
                ((fm_valid["fm_node1"] == node_b) & (fm_valid["fm_node2"] == node_a))
            )
            fm_candidates = fm_valid[fm_pair_mask]

           
            # ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î‡πÄ‡∏•‡∏¢ ‚Üí FLAPPING
            if fm_candidates.empty:
                print(
                    f"Row {idx}: ME={node_a}, Target={node_b}\n"
                    f"       No match in FM for link pair ({node_a} ‚Üî {node_b})\n"
                    f"       Optical Time: {begin_t} ‚Üí {end_t}\n"
                    f"       ‚Üí FLAPPING ‚úÖ (no FM link found)"
                )
                result_rows.append(row)
                continue

            # ‡∏°‡∏µ‡∏Ñ‡∏π‡πà‡πÇ‡∏´‡∏ô‡∏î‡πÉ‡∏ô FM ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ß‡∏•‡∏≤ overlap (‡∏°‡∏µ‡∏™‡∏±‡∏Å‡∏≠‡∏±‡∏ô overlap = MATCHED)
            any_overlap = False
            multi_logs = []
            for j, fm_r in fm_candidates.iterrows():
                fm_a, fm_b = fm_r["fm_node1"], fm_r["fm_node2"]
                occ_t = fm_r.get("Occurrence Time", pd.NaT)
                clr_t = fm_r.get("Clear Time", pd.NaT)

                overlap = (
                    pd.notna(occ_t)
                    and pd.notna(clr_t)
                    and (occ_t <= end_t)
                    and (clr_t >= begin_t)
                )
                any_overlap = any_overlap or overlap

                # ‡πÄ‡∏Å‡πá‡∏ö log ‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
                multi_logs.append(
                    f"           FM Link: {fm_a}-{fm_b}, FM Time: {occ_t} ‚Üí {clr_t} "
                    f"({'Overlap ‚úÖ' if overlap else 'No overlap'})"
                )

            # ‚úÖ ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ FLAPPING ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
            if not any_overlap:
                if len(multi_logs) == 1:
                    header = (
                        f"Row {idx}: ME={node_a}, Target={node_b}\n"
                        f"       Found match in FM ‚Üí Link: {fm_candidates.iloc[0]['fm_node1']}-{fm_candidates.iloc[0]['fm_node2']}\n"
                        f"       Optical Time: {begin_t} ‚Üí {end_t}\n"
                    )
                    print(header + multi_logs[0] + f"\n       Time overlap: False  ‚Üí FLAPPING ‚úÖ")
                else:
                    print(
                        f"Row {idx}: ME={node_a}, Target={node_b}\n"
                        f"       Found multiple FM matches:\n" +
                        "\n".join(multi_logs) + "\n" +
                        f"       Optical Time: {begin_t} ‚Üí {end_t}\n"
                        f"       Overall Result ‚Üí FLAPPING ‚úÖ"
                    )

                # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ result ‡∏ñ‡πâ‡∏≤ '‡πÑ‡∏°‡πà overlap ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î' = FLAPPING
                result_rows.append(row)

        return pd.DataFrame(result_rows)

    # -------------------- View Preparation --------------------
    @staticmethod
    def prepare_view(df_nomatch: pd.DataFrame) -> pd.DataFrame:
        # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå - ‡πÄ‡∏û‡∏¥‡πà‡∏° Site Name ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Granularity ‡πÅ‡∏•‡∏∞ ME
        view_cols = [
            "Begin Time", "End Time", "Granularity", "Site Name", "ME", "ME IP", "Measure Object",
            "Max Value of Input Optical Power(dBm)", "Min Value of Input Optical Power(dBm)", "Max - Min (dB)"
        ]
        view_cols = [c for c in view_cols if c in df_nomatch.columns]
        df_view = df_nomatch[view_cols].copy()

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠ format ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°
        num_cols = [
            "Max Value of Input Optical Power(dBm)",
            "Min Value of Input Optical Power(dBm)",
            "Max - Min (dB)"
        ]
        num_cols = [c for c in num_cols if c in df_view.columns]
        if num_cols:
            df_view.loc[:, num_cols] = df_view[num_cols].apply(pd.to_numeric, errors="coerce")
        return df_view

    # -------------------- Rendering --------------------
    def render(self, df_nomatch: pd.DataFrame) -> None:
        st.markdown("### OSC Power Flapping (No Alarm Match)")

        if df_nomatch.empty:
            st.success("No unmatched fiber flapping records found")
            return

        # Cascading filter
        df_nomatch_filtered, _sel = cascading_filter(
            df_nomatch,
            cols=["Site Name", "ME", "Measure Object"],
            ns="fiber",
            labels={"Site Name": "Site Name", "ME": "Managed Element"},
            clear_text="Clear Fiber Filters",
        )
        st.caption(f"Fiber Flapping (showing {len(df_nomatch_filtered)}/{len(df_nomatch)} rows)")

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        df_view = self.prepare_view(df_nomatch_filtered)

        # Highlight ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "Max - Min (dB)" > threshold
        if "Max - Min (dB)" in df_view.columns:
            styled_df = (
                df_view.style
                .apply(
                    lambda _:
                        ['background-color:#ff4d4d; color:white' if (v > self.threshold) else ''
                         for v in df_view["Max - Min (dB)"]],
                    subset=["Max - Min (dB)"]
                )
                .format({
                    "Max Value of Input Optical Power(dBm)": "{:.2f}",
                    "Min Value of Input Optical Power(dBm)": "{:.2f}",
                    "Max - Min (dB)": "{:.2f}",
                })
            )
            st.write(styled_df)
        else:
            st.dataframe(df_view, use_container_width=True)
        
        # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ view
        return df_view

    # -------------------- Weekly KPI (7-Day Summary) --------------------
    def render_weekly_summary(self, df_nomatch: pd.DataFrame) -> None:
        """Summary KPI: Flapping sites per day (7-day view with drill-down + graph at the end)"""
        if df_nomatch.empty:
            st.success("No unmatched fiber flapping records in past 7 days")
            return

        df_nomatch = df_nomatch.copy()
        df_nomatch["Date"] = pd.to_datetime(df_nomatch["Begin Time"]).dt.date

        # ‡∏´‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô start ‚Üí end
        start_date = df_nomatch["Date"].min()
        end_date   = df_nomatch["Date"].max()
        st.markdown(f"### Fiber Flapping Summary (Past 7 Days: {start_date} ‚Üí {end_date})")

        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô site ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô
        daily_counts = (
            df_nomatch.groupby("Date")["ME"].nunique().reset_index()
            .rename(columns={"ME": "Sites"})
        )

        # ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        if "selected_day" not in st.session_state:
            st.session_state["selected_day"] = None

        # ‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô
        cols = st.columns(len(daily_counts))
        for i, row in daily_counts.iterrows():
            day = row["Date"]
            count = row["Sites"]
            with cols[i]:
                st.metric(label=str(day), value=f"{count} sites")
                if st.button("Show Details", key=f"btn_{day}"):
                    st.session_state["selected_day"] = day

        # Drill-down ‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        if st.session_state["selected_day"]:
            sel_day = st.session_state["selected_day"]
            sel = df_nomatch[df_nomatch["Date"] == sel_day]

           
            st.markdown(f"#### Details for {sel_day}")

            # üîπ ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô flapping ‡∏ï‡πà‡∏≠ Site Name (‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà)
            if not sel.empty and "Site Name" in sel.columns and "ME" in sel.columns and "Measure Object" in sel.columns:
                # ‡∏î‡∏∂‡∏á Target ME ‡∏à‡∏≤‡∏Å Measure Object (‡πÉ‡∏ä‡πâ regex ‡∏î‡∏∂‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Target ME)
                sel["Target ME"] = sel["Measure Object"].apply(
                    lambda x: re.search(r"\(([^)]+)\)", str(x)).group(1) if pd.notna(x) and re.search(r"\(([^)]+)\)", str(x)) else None
                )
                summary_rows = []
                for site, group in sel.groupby("Site Name"):
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î link ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ (ME + Target ME)
                    link_pairs = group[["ME", "Target ME"]].drop_duplicates()
                    n_links = len(link_pairs)
                    n_times = len(group)
                    summary_rows.append(f"{site} ({n_links} link{'s' if n_links > 1 else ''} {n_times} time{'s' if n_times > 1 else ''})")

                counts_str = " ".join(summary_rows)
                st.markdown(counts_str)
                
            if sel.empty:
                st.info("No flapping records on this day")
            else:
                # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡πÑ‡∏°‡πà‡∏°‡∏µ Target ME, Date)
                view_cols = [
                    "Begin Time", "End Time", "Site Name", "ME", "ME IP", "Measure Object",
                    "Max Value of Input Optical Power(dBm)",
                    "Min Value of Input Optical Power(dBm)", "Max - Min (dB)"
                ]
                view_cols = [c for c in view_cols if c in sel.columns]
                sel = sel[view_cols]

                # ‚úÖ ‡∏ó‡∏≥ highlight ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Max - Min (dB)
                if "Max - Min (dB)" in sel.columns:
                    styled_sel = (
                        sel.style
                        .apply(
                            lambda _:
                                ['background-color:#ff4d4d; color:white' if (v > self.threshold) else ''
                                 for v in sel["Max - Min (dB)"]],
                            subset=["Max - Min (dB)"]
                        )
                        .format({
                            "Max Value of Input Optical Power(dBm)": "{:.2f}",
                            "Min Value of Input Optical Power(dBm)": "{:.2f}",
                            "Max - Min (dB)": "{:.2f}",
                        })
                    )
                    st.write(styled_sel)
                else:
                    st.dataframe(sel, use_container_width=True)
                    

        # üìä ‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏ß‡∏° (‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î)
        if not daily_counts.empty:
            fig = px.bar(daily_counts, x="Date", y="Sites", text="Sites", title="No Fiber Break Alarm Match(Fiber Flapping)")
            fig.update_traces(textposition="outside")
            fig.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)

    # -------------------- Export helper (NEW) --------------------
    @staticmethod
    def _select_view_columns(df: pd.DataFrame) -> pd.DataFrame:
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô drill-down ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export/report)
        """
        view_cols = [
            "Begin Time", "End Time", "Site Name", "ME", "Measure Object",
            "Max Value of Input Optical Power(dBm)",
            "Min Value of Input Optical Power(dBm)",
            "Max - Min (dB)"
        ]
        have = [c for c in view_cols if c in df.columns]
        out = df[have].copy()

        num_cols = [c for c in [
            "Max Value of Input Optical Power(dBm)",
            "Min Value of Input Optical Power(dBm)",
            "Max - Min (dB)"
        ] if c in out.columns]
        if num_cols:
            out.loc[:, num_cols] = out[num_cols].apply(pd.to_numeric, errors="coerce").round(2)
        return out

    def build_daily_tables(self, df_nomatch: pd.DataFrame) -> "OrderedDict[str, pd.DataFrame]":
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô -> DataFrame (‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô drill-down) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export
        ‡πÄ‡∏ä‡πà‡∏ô {"2025-06-17": df_table, "2025-06-18": df_table, ...}
        """
        if df_nomatch.empty:
            self.daily_tables = OrderedDict()
            return self.daily_tables

        df = df_nomatch.copy()
        df["Date"] = pd.to_datetime(df["Begin Time"]).dt.date

        tables = OrderedDict()
        for day, g in df.sort_values("Begin Time").groupby("Date", sort=True):
            tables[str(day)] = self._select_view_columns(g)
        self.daily_tables = tables
        return tables

    # -------------------- Orchestration --------------------
    def process(self) -> None:
        # 1) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df_optical_norm = self.normalize_optical()
        df_fm_norm, link_col = self.normalize_fm()

        # 2) ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° threshold
        df_filtered = self.filter_optical_by_threshold(df_optical_norm)

        # 3) ‡∏´‡∏≤ no-match (‡∏î‡πâ‡∏ß‡∏¢ logic ‡πÉ‡∏´‡∏°‡πà)
        df_nomatch = self.find_nomatch(df_filtered, df_fm_norm, link_col)

        # 4) ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å
        self.render(df_nomatch)

        # 5) Weekly Summary KPI + ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
        self.render_weekly_summary(df_nomatch)

    def prepare(self) -> None:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Summary/PDF (‡πÑ‡∏°‡πà render UI)
        """
        # 1) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df_optical_norm = self.normalize_optical()
        df_fm_norm, link_col = self.normalize_fm()

        # 2) ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° threshold
        df_filtered = self.filter_optical_by_threshold(df_optical_norm)

        # 3) ‡∏´‡∏≤ no-match (‡∏î‡πâ‡∏ß‡∏¢ logic ‡πÉ‡∏´‡∏°‡πà)
        df_nomatch = self.find_nomatch(df_filtered, df_fm_norm, link_col)

        # 4) ‡∏™‡∏£‡πâ‡∏≤‡∏á abnormal tables
        if not df_nomatch.empty:
            df_view = self._select_view_columns(df_nomatch)
            self.df_abnormal = df_view.copy()
            self.df_abnormal_by_type = {
                "Fiber Flapping": df_view
            }
        else:
            self.df_abnormal = pd.DataFrame()
            self.df_abnormal_by_type = {}

        # 5) ‡∏™‡∏£‡πâ‡∏≤‡∏á daily tables ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export
        self.build_daily_tables(df_nomatch)

    @property
    def df_abnormal(self):
        return getattr(self, '_df_abnormal', pd.DataFrame())

    @df_abnormal.setter
    def df_abnormal(self, value):
        self._df_abnormal = value

    @property
    def df_abnormal_by_type(self):
        return getattr(self, '_df_abnormal_by_type', {})

    @df_abnormal_by_type.setter
    def df_abnormal_by_type(self, value):
        self._df_abnormal_by_type = value

    
